{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import datetime\n",
    "from langchain.prompts import PromptTemplate\n",
    "from openai import OpenAI\n",
    "from assistants import generate_response\n",
    "from tqdm import tqdm\n",
    "from helpers import extract_scores\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [01:12, 69.43it/s]\n"
     ]
    }
   ],
   "source": [
    "query = 'AI ML NLP deeplearning reinforcement learning'\n",
    "\n",
    "current_date = datetime.datetime.now(datetime.timezone.utc)\n",
    "seven_days_ago = current_date - datetime.timedelta(days=7)\n",
    "\n",
    "\n",
    "client = arxiv.Client(num_retries=20, page_size=500)\n",
    "search = arxiv.Search(query=query,\n",
    "                      max_results = 5000, \n",
    "                      sort_by=arxiv.SortCriterion.SubmittedDate)\n",
    "results = client.results(search)\n",
    "\n",
    "jresults = []\n",
    "\n",
    "for result in tqdm(results):\n",
    "    if result is not None and result.primary_category.startswith(\"cs\") and result.primary_category != \"cs.SE\":\n",
    "        r = dict()\n",
    "        r[\"entry_id\"] = result.entry_id\n",
    "        r[\"updated\"] = str(result.updated)\n",
    "        r[\"published\"] = str(result.published)\n",
    "        r[\"title\"] = result.title\n",
    "        r[\"summary\"] = result.summary\n",
    "        r[\"primary_category\"] = result.primary_category\n",
    "        r[\"categories\"] = result.categories\n",
    "        r[\"links\"] = [str(link) for link in result.links]\n",
    "        r[\"pdf_url\"] = result.pdf_url\n",
    "        jresults.append(r)\n",
    "        \n",
    "results_list = [x for x in jresults if (datetime.datetime.strptime(x['updated'], '%Y-%m-%d %H:%M:%S%z')>=seven_days_ago) \\\n",
    "                        or (datetime.datetime.strptime(x['published'], '%Y-%m-%d %H:%M:%S%z')>=seven_days_ago) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 968/968 [1:08:27<00:00,  4.24s/it]  \n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Title: {title}\n",
    "\n",
    "Summary: {summary}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "OPENAI_API_KEY_Assiatant = os.environ.get('OPENAI_API_KEY_Assiatant')\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY_Assiatant)\n",
    "\n",
    "for entry in tqdm(results_list):\n",
    "    title = entry['title']\n",
    "    summary = entry['summary']\n",
    "\n",
    "    message_body = prompt.format(title=title,summary=summary)\n",
    "    rating = generate_response(client,message_body)\n",
    "\n",
    "    entry['raw_score_data'] = rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "968it [00:00, 94085.84it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx,data in tqdm(enumerate(results_list)):\n",
    "    score_data = data['raw_score_data']\n",
    "    extracted_data = extract_scores(score_data)\n",
    "    \n",
    "    results_list[idx] = results_list[idx] |extracted_data\n",
    "\n",
    "final_data = []\n",
    "for data in results_list:\n",
    "    record = {}\n",
    "    record['title'] = data['title']\n",
    "    record['summary'] = data['summary']\n",
    "    record['link'] = data['links'][0]\n",
    "    record['score']= data['score']\n",
    "    record['innovation']= data['innovation']\n",
    "    record['newness']=data['newness']\n",
    "    record['potential']=data['potential']\n",
    "    record['clarity']= data['clarity']\n",
    "    record['relevance']= data['relevance']\n",
    "    \n",
    "    final_data.append(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_data)\n",
    "df = df.sort_values(by='score', ascending=False)\n",
    "df = df.reset_index(drop=True) \n",
    "\n",
    "csv_filename = \"./data/data_14_02_2024.csv\"\n",
    "\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "markdown_text = \"\"\n",
    "for index, row in df.head(10).iterrows():\n",
    "    markdown_text += f\"#### {index+1}.{row['title']}. [Link]({row['link']}) \\n\"\n",
    "    markdown_text += f\"#### GPT Score: {row['score']}\\n\"\n",
    "    markdown_text += f\"Innovation:{row['innovation']}, Newness:{row['newness']}, Potential:{row['potential']}, Clarity:{row['clarity']}, Relevance:{row['relevance']}\\n\" \n",
    "    markdown_text += f\"### Summary\\n\"\n",
    "    markdown_text += f\"{row['summary']}\\n\\n\"\n",
    "\n",
    "\n",
    "# Saving the Markdown formatted text to a file\n",
    "markdown_filename = \"./data/markdown_text.md\"\n",
    "\n",
    "with open(markdown_filename, 'w') as file:\n",
    "    file.write(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewAI_wsl-e6LWwXta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
